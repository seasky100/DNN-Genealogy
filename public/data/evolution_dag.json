[
  {
    "date": "1998.11.01", 
    "training": [
      "3.2.1.SGD"
    ], 
    "parents": [], 
    "architecture": [
      "2.2.1.1.plain", 
      "2.2.2.2.2.sigmoid"
    ], 
    "application": [
      "1.1.1.general recognition"
    ], 
    "url": "http://ieeexplore.ieee.org/abstract/document/726791/", 
    "citation": "10831", 
    "ID": "leNet", 
    "names": []
  }, 
  {
    "date": "2012.12.03", 
    "training": [
      "3.4.1.dropout", 
      "3.2.1.SGD with momentum", 
      "3.4.2.weight decay", 
      "2.2.2.2.1.1.standard relu"
    ], 
    "parents": [
      {
        "link_info_l": "", 
        "ID": "leNet", 
        "link_info_s": ""
      }
    ], 
    "architecture": [
      "2.2.1.1.plain", 
      "2.2.2.2.1.1.standard relu"
    ], 
    "application": [
      "1.1.1.general recognition"
    ], 
    "url": "https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks", 
    "citation": "18438", 
    "ID": "alexNet", 
    "names": [
      {
        "imagenet val top5": 15.4, 
        "imageNet val top1": 36.7, 
        "name": "alexNet", 
        "cifar10": null, 
        "params": 60.0, 
        "cifar100": null, 
        "SVHN": null
      }
    ]
  }, 
  {
    "date": "2014.09.17", 
    "training": [
      "3.4.1.dropout", 
      "3.2.1.SGD with momentum", 
      "3.4.2.weight decay", 
      "2.2.2.2.1.1.standard relu"
    ], 
    "parents": [
      {
        "link_info_l": "less computation cost", 
        "ID": "VGG", 
        "link_info_s": "less computation cost"
      }
    ], 
    "architecture": [
      "2.2.1.3.multi-branch", 
      "2.2.2.2.1.1.standard relu"
    ], 
    "application": [
      "1.1.1.general recognition"
    ], 
    "url": "https://arxiv.org/abs/1409.4842", 
    "citation": "5591", 
    "ID": "inception", 
    "names": [
      {
        "imagenet val top5": 6.67, 
        "imageNet val top1": null, 
        "name": "inception", 
        "cifar10": null, 
        "params": 6.8, 
        "cifar100": null, 
        "SVHN": null
      }
    ]
  }, 
  {
    "date": "2014.09.04", 
    "training": [
      "3.4.1.dropout", 
      "3.2.1.SGD with momentum", 
      "3.4.2.weight decay", 
      "2.2.2.2.1.1.standard relu"
    ], 
    "parents": [
      {
        "link_info_l": "deeper;conv7=>2*conv3", 
        "ID": "alexNet", 
        "link_info_s": "deeper;conv7=>2*conv3"
      }
    ], 
    "architecture": [
      "2.2.1.1.plain", 
      "2.2.2.2.1.1.standard relu"
    ], 
    "application": [
      "1.1.1.general recognition"
    ], 
    "url": "https://arxiv.org/abs/1409.1556", 
    "citation": "8205", 
    "ID": "VGG", 
    "names": [
      {
        "imagenet val top5": 7.3, 
        "imageNet val top1": 25.5, 
        "name": "vgg19", 
        "cifar10": null, 
        "params": 144.0, 
        "cifar100": null, 
        "SVHN": null
      }, 
      {
        "imagenet val top5": 8.1, 
        "imageNet val top1": 25.6, 
        "name": "vgg16", 
        "cifar10": null, 
        "params": 138.0, 
        "cifar100": null, 
        "SVHN": null
      }
    ]
  }, 
  {
    "date": "2015.12.02", 
    "training": [
      "3.4.6.LSR", 
      "3.4.1.dropout", 
      "3.2.1.SGD with momentum", 
      "3.4.2.weight decay"
    ], 
    "parents": [
      {
        "link_info_l": "easy to scale up", 
        "ID": "inception", 
        "link_info_s": "easy to scale up"
      }
    ], 
    "architecture": [
      "2.2.1.3.multi-branch", 
      "2.2.2.2.1.1.standard relu"
    ], 
    "application": [
      "1.1.1.general recognition"
    ], 
    "url": "https://arxiv.org/abs/1512.00567", 
    "citation": "794", 
    "ID": "inception_rethink", 
    "names": [
      {
        "imagenet val top5": 4.2, 
        "imageNet val top1": 18.77, 
        "name": "inception_v3", 
        "cifar10": null, 
        "params": 23.8, 
        "cifar100": null, 
        "SVHN": null
      }, 
      {
        "imagenet val top5": null, 
        "imageNet val top1": null, 
        "name": "inception_v2", 
        "cifar10": null, 
        "params": 0.0, 
        "cifar100": null, 
        "SVHN": null
      }
    ]
  }, 
  {
    "date": "2015.11.03", 
    "training": [], 
    "parents": [
      {
        "link_info_l": "inspired by its gate mechanism", 
        "ID": "LSTM", 
        "link_info_s": "inspired by its gate mechanism"
      }, 
      {
        "link_info_l": "enables to train extremely deep models directly from scratch", 
        "ID": "VGG", 
        "link_info_s": "enables to train extremely deep models directly from scratch"
      }
    ], 
    "architecture": [
      "2.2.1.2.residual", 
      "2.2.2.2.1.1.standard relu"
    ], 
    "application": [
      "1.1.1.general recognition"
    ], 
    "url": "https://arxiv.org/pdf/1505.00387.pdf", 
    "citation": "320", 
    "ID": "highwayNets", 
    "names": [
      {
        "imagenet val top5": null, 
        "imageNet val top1": null, 
        "name": "highwayNets", 
        "cifar10": 7.76, 
        "params": 2.3, 
        "cifar100": null, 
        "SVHN": null
      }
    ]
  }, 
  {
    "date": "2015.12.10", 
    "training": [
      "3.4.4.batch normalization", 
      "3.2.1.SGD with momentum", 
      "3.4.2.weight decay", 
      "3.1.7.he_normal"
    ], 
    "parents": [
      {
        "link_info_l": "add residual connections", 
        "ID": "VGG", 
        "link_info_s": "add residual connections"
      }, 
      {
        "link_info_l": "remove gate", 
        "ID": "highwayNets", 
        "link_info_s": "remove gate"
      }
    ], 
    "architecture": [
      "2.2.1.2.residual", 
      "2.2.2.2.1.1.standard relu"
    ], 
    "application": [
      "1.1.1.general recognition"
    ], 
    "url": "https://arxiv.org/abs/1512.03385", 
    "citation": "5464", 
    "ID": "resNet", 
    "names": [
      {
        "imagenet val top5": null, 
        "imageNet val top1": null, 
        "name": "resNet_v1_56_cifar", 
        "cifar10": 6.97, 
        "params": 0.86, 
        "cifar100": 25.16, 
        "SVHN": null
      }, 
      {
        "imagenet val top5": null, 
        "imageNet val top1": null, 
        "name": "resNet_v1_110_cifar", 
        "cifar10": 6.43, 
        "params": 1.7, 
        "cifar100": 25.16, 
        "SVHN": null
      }, 
      {
        "imagenet val top5": 7.1, 
        "imageNet val top1": 24.1, 
        "name": "resNet_v1_50", 
        "cifar10": null, 
        "params": 25.6, 
        "cifar100": null, 
        "SVHN": null
      }, 
      {
        "imagenet val top5": 5.71, 
        "imageNet val top1": 21.43, 
        "name": "resNet_v1_152", 
        "cifar10": null, 
        "params": 60.4, 
        "cifar100": null, 
        "SVHN": null
      }
    ]
  }, 
  {
    "date": "2016.02.23", 
    "training": [
      "3.2.3.RMSprop", 
      "scaling of the residuals", 
      "3.4.1.dropout", 
      "3.2.1.SGD with momentum", 
      "3.4.2.weight decay"
    ], 
    "parents": [
      {
        "link_info_l": "combine resnet with inception", 
        "ID": "inception_rethink", 
        "link_info_s": "combine resnet with inception"
      }, 
      {
        "link_info_l": "combine resnet with inception", 
        "ID": "resNet", 
        "link_info_s": "combine resnet with inception"
      }
    ], 
    "architecture": [
      "2.2.1.2.residual", 
      "2.2.1.3.multi-branch", 
      "2.2.2.2.1.1.standard relu"
    ], 
    "application": [
      "1.1.1.general recognition"
    ], 
    "url": "https://arxiv.org/abs/1602.07261", 
    "citation": "480", 
    "ID": "inception_resNet", 
    "names": [
      {
        "imagenet val top5": 3.7, 
        "imageNet val top1": 17.8, 
        "name": "inception_resNet", 
        "cifar10": null, 
        "params": 55.8, 
        "cifar100": null, 
        "SVHN": null
      }
    ]
  }, 
  {
    "date": "2016.05.23", 
    "training": [
      "3.4.4.batch normalization", 
      "3.2.1.SGD with momentum", 
      "3.4.2.weight decay", 
      "3.4.1.dropout"
    ], 
    "parents": [
      {
        "link_info_l": "wider instead of deeper", 
        "ID": "resNet", 
        "link_info_s": "wider instead of deeper for computation efficiency"
      }
    ], 
    "architecture": [
      "2.2.1.2.residual", 
      "2.2.2.2.1.1.standard relu"
    ], 
    "application": [
      "1.1.1.general recognition"
    ], 
    "url": "https://arxiv.org/abs/1605.07146", 
    "citation": "285", 
    "ID": "WRN", 
    "names": [
      {
        "imagenet val top5": null, 
        "imageNet val top1": null, 
        "name": "wideResNet_16_4", 
        "cifar10": 5.24, 
        "params": 2.9, 
        "cifar100": 23.91, 
        "SVHN": 1.64
      }, 
      {
        "imagenet val top5": null, 
        "imageNet val top1": null, 
        "name": "wideResNet_28_10", 
        "cifar10": 3.89, 
        "params": 36.0, 
        "cifar100": 18.85, 
        "SVHN": 1.64
      }, 
      {
        "imagenet val top5": 5.79, 
        "imageNet val top1": 21.9, 
        "name": "wideResNet-50-2", 
        "cifar10": null, 
        "params": 0.0, 
        "cifar100": null, 
        "SVHN": null
      }
    ]
  }, 
  {
    "date": "2016.05.25", 
    "training": [
      "3.4.4.batch normalization", 
      "3.2.1.SGD with momentum", 
      "3.4.2.weight decay", 
      "3.4.1.dropout"
    ], 
    "parents": [
      {
        "link_info_l": "generalizes ResNets and standard CNNs", 
        "ID": "resNet", 
        "link_info_s": "generalizes ResNets and standard CNNs"
      }
    ], 
    "architecture": [
      "2.2.1.2.residual", 
      "2.2.2.2.1.1.standard relu"
    ], 
    "application": [
      "1.1.1.general recognition"
    ], 
    "url": "https://arxiv.org/abs/1603.08029", 
    "citation": "37", 
    "ID": "RIR", 
    "names": [
      {
        "imagenet val top5": null, 
        "imageNet val top1": null, 
        "name": "resNet-in-resent", 
        "cifar10": 5.01, 
        "params": 0.0, 
        "cifar100": 22.9, 
        "SVHN": null
      }
    ]
  }, 
  {
    "date": "2016.05.24", 
    "training": [
      "3.4.3.drop path", 
      "3.4.4.batch normalization", 
      "3.2.1.SGD with momentum", 
      "3.4.2.weight decay", 
      "3.4.1.dropout"
    ], 
    "parents": [
      {
        "link_info_l": "shows that explicit residual learning is not a requirement for building ultra-deep neural networks", 
        "ID": "resNet", 
        "link_info_s": "shows that explicit residual learning is not a requirement for building ultra-deep neural networks"
      }
    ], 
    "architecture": [
      "2.2.1.3.multi-branch", 
      "2.2.2.2.1.1.standard relu"
    ], 
    "application": [
      "1.1.1.general recognition"
    ], 
    "url": "https://arxiv.org/abs/1605.07648", 
    "citation": "71", 
    "ID": "fractalNet", 
    "names": [
      {
        "imagenet val top5": null, 
        "imageNet val top1": null, 
        "name": "fractalNet-40", 
        "cifar10": 5.24, 
        "params": 22.9, 
        "cifar100": 22.49, 
        "SVHN": null
      }, 
      {
        "imagenet val top5": null, 
        "imageNet val top1": null, 
        "name": "fractalNet-20", 
        "cifar10": 5.22, 
        "params": 38.6, 
        "cifar100": 23.3, 
        "SVHN": null
      }
    ]
  }, 
  {
    "date": "2016.11.16", 
    "training": [
      "3.4.7.pre-activation", 
      "3.4.4.batch normalization", 
      "3.2.1.SGD with momentum", 
      "3.4.2.weight decay"
    ], 
    "parents": [
      {
        "link_info_l": "add a new dimension called \"\u201ccardinality\"", 
        "ID": "resNet", 
        "link_info_s": "add a new dimension called \"\u201ccardinality\""
      }, 
      {
        "link_info_l": "exploiting the split-transform-merge strategy in an easy, extensible way", 
        "ID": "inception", 
        "link_info_s": "exploiting the split-transform-merge strategy in an easy, extensible way"
      }
    ], 
    "architecture": [
      "2.2.1.2.residual", 
      "2.2.1.3.multi-branch", 
      "2.2.2.2.1.1.standard relu"
    ], 
    "application": [
      "1.1.1.general recognition"
    ], 
    "url": "https://arxiv.org/abs/1611.05431", 
    "citation": "134", 
    "ID": "resNeXt", 
    "names": [
      {
        "imagenet val top5": 5.3, 
        "imageNet val top1": 20.4, 
        "name": "ResNeXt", 
        "cifar10": 3.58, 
        "params": 25.0, 
        "cifar100": 17.31, 
        "SVHN": null
      }
    ]
  }, 
  {
    "date": "2016.08.25", 
    "training": [
      "3.4.1.dropout", 
      "3.2.1.SGD with nesterov momentum", 
      "3.4.2.weight decay", 
      "3.1.7.he_normal"
    ], 
    "parents": [
      {
        "link_info_l": "dense residual connection; change add to concate", 
        "ID": "resNet", 
        "link_info_s": "dense residual connection; change add to concate"
      }
    ], 
    "architecture": [
      "2.2.1.2.residual", 
      "2.2.2.2.1.1.standard relu"
    ], 
    "application": [
      "1.1.1.general recognition"
    ], 
    "url": "https://arxiv.org/abs/1608.06993", 
    "citation": "378", 
    "ID": "denseNet", 
    "names": [
      {
        "imagenet val top5": null, 
        "imageNet val top1": null, 
        "name": "denseNet_40_12", 
        "cifar10": 5.24, 
        "params": 1.0, 
        "cifar100": 24.42, 
        "SVHN": 1.79
      }, 
      {
        "imagenet val top5": null, 
        "imageNet val top1": null, 
        "name": "denseNet_100_12", 
        "cifar10": 4.1, 
        "params": 7.2, 
        "cifar100": 20.2, 
        "SVHN": 1.67
      }, 
      {
        "imagenet val top5": null, 
        "imageNet val top1": null, 
        "name": "denseNet_100_24", 
        "cifar10": 3.74, 
        "params": 27.2, 
        "cifar100": 19.25, 
        "SVHN": 1.59
      }, 
      {
        "imagenet val top5": null, 
        "imageNet val top1": null, 
        "name": "denseNet-BC(l=100, k=12)", 
        "cifar10": 4.51, 
        "params": 0.8, 
        "cifar100": 22.27, 
        "SVHN": 1.76
      }, 
      {
        "imagenet val top5": null, 
        "imageNet val top1": null, 
        "name": "denseNet-BC(l=250, k=24)", 
        "cifar10": 3.62, 
        "params": 15.3, 
        "cifar100": 17.6, 
        "SVHN": 1.74
      }, 
      {
        "imagenet val top5": null, 
        "imageNet val top1": null, 
        "name": "denseNet-BC(l=190, k=40)", 
        "cifar10": 3.46, 
        "params": 25.6, 
        "cifar100": 17.18, 
        "SVHN": null
      }, 
      {
        "imagenet val top5": 7.71, 
        "imageNet val top1": 25.02, 
        "name": "denseNet_121", 
        "cifar10": null, 
        "params": 8.1, 
        "cifar100": null, 
        "SVHN": null
      }, 
      {
        "imagenet val top5": 6.34, 
        "imageNet val top1": 22.58, 
        "name": "denseNet_201", 
        "cifar10": null, 
        "params": 20.2, 
        "cifar100": null, 
        "SVHN": null
      }
    ]
  }, 
  {
    "date": "2016.02.24", 
    "training": [
      "3.4.1.dropout", 
      "3.2.1.SGD with momentum", 
      "3.4.2.weight decay"
    ], 
    "parents": [
      {
        "link_info_l": "same performance with 50x less parameters", 
        "ID": "alexNet", 
        "link_info_s": ""
      }, 
      {
        "link_info_l": "exploiting the split-transform-merge strategy in an easy, extensible way", 
        "ID": "inception", 
        "link_info_s": ""
      }
    ], 
    "architecture": [
      "2.2.1.3.multi-branch", 
      "2.2.2.2.1.1.standard relu", 
      "2.2.1.2.residual"
    ], 
    "application": [
      "1.1.1.general recognition"
    ], 
    "url": "https://arxiv.org/abs/1602.07360", 
    "citation": "264", 
    "ID": "squeezeNet", 
    "names": [
      {
        "imagenet val top5": 17.5, 
        "imageNet val top1": 39.6, 
        "name": "squeezeNet", 
        "cifar10": null, 
        "params": 1.24, 
        "cifar100": null, 
        "SVHN": null
      }
    ]
  }, 
  {
    "date": "2017.06.07", 
    "training": [
      "3.1.11.dirac", 
      "3.4.4.batch normalization", 
      "3.2.1.SGD with momentum", 
      "3.4.2.weight decay", 
      "3.4.1.dropout"
    ], 
    "parents": [
      {
        "link_info_l": "train a deep network without residual connections", 
        "ID": "resNet", 
        "link_info_s": ""
      }
    ], 
    "architecture": [
      "2.2.1.1.plain", 
      "2.2.2.2.1.4.CRelu"
    ], 
    "application": [
      "1.1.1.general recognition"
    ], 
    "url": "https://arxiv.org/abs/1706.00388", 
    "citation": "4", 
    "ID": "diracNet", 
    "names": [
      {
        "imagenet val top5": null, 
        "imageNet val top1": null, 
        "name": "diracNet-28-5", 
        "cifar10": 3.16, 
        "params": 9.1, 
        "cifar100": 23.44, 
        "SVHN": null
      }, 
      {
        "imagenet val top5": null, 
        "imageNet val top1": null, 
        "name": "diracNet-28-10", 
        "cifar10": 4.75, 
        "params": 36.5, 
        "cifar100": 21.54, 
        "SVHN": null
      }, 
      {
        "imagenet val top5": 10.88, 
        "imageNet val top1": 30.37, 
        "name": "diracNet-18", 
        "cifar10": null, 
        "params": 11.7, 
        "cifar100": null, 
        "SVHN": null
      }, 
      {
        "imagenet val top5": 9.34, 
        "imageNet val top1": 27.79, 
        "name": "diracNet-34", 
        "cifar10": null, 
        "params": 21.8, 
        "cifar100": null, 
        "SVHN": null
      }
    ]
  }, 
  {
    "date": "2017.12.01", 
    "training": [
      "neural architecture search by reinforcement learning"
    ], 
    "parents": [
      {
        "link_info_l": "offer guides for the predeterimined structures", 
        "ID": "resNet", 
        "link_info_s": ""
      }, 
      {
        "link_info_l": "", 
        "ID": "inception", 
        "link_info_s": ""
      }
    ], 
    "architecture": [
      "2.2.1.2.residual", 
      "2.2.1.3.multi-branch"
    ], 
    "application": [
      "1.1.1.general recognition"
    ], 
    "url": "https://arxiv.org/abs/1707.07012", 
    "citation": "17", 
    "ID": "nasNet", 
    "names": [
      {
        "imagenet val top5": null, 
        "imageNet val top1": null, 
        "name": "nasNet_cifar", 
        "cifar10": 2.65, 
        "params": 3.3, 
        "cifar100": null, 
        "SVHN": null
      }, 
      {
        "imagenet val top5": 3.8, 
        "imageNet val top1": 17.3, 
        "name": "nasNet_small", 
        "cifar10": null, 
        "params": 88.9, 
        "cifar100": null, 
        "SVHN": null
      }, 
      {
        "imagenet val top5": 8.4, 
        "imageNet val top1": 26.0, 
        "name": "nasNet_large", 
        "cifar10": null, 
        "params": 5.3, 
        "cifar100": null, 
        "SVHN": null
      }
    ]
  }, 
  {
    "date": "2018.02.06", 
    "training": [], 
    "parents": [
      {
        "link_info_l": "", 
        "ID": "resNet", 
        "link_info_s": ""
      }, 
      {
        "link_info_l": "", 
        "ID": "denseNet", 
        "link_info_s": ""
      }
    ], 
    "architecture": [
      "2.2.1.2.residual", 
      "2.2.1.3.multi-branch"
    ], 
    "application": [
      "1.1.1.general recognition"
    ], 
    "url": "https://arxiv.org/abs/1802.01808", 
    "citation": "0", 
    "ID": "mixNet", 
    "names": [
      {
        "imagenet val top5": null, 
        "imageNet val top1": null, 
        "name": "mixNet", 
        "cifar10": null, 
        "params": 0.0, 
        "cifar100": null, 
        "SVHN": null
      }
    ]
  }, 
  {
    "date": "1986.12.01", 
    "training": [], 
    "parents": [], 
    "architecture": [], 
    "application": [
      "1.2.NLP"
    ], 
    "url": "https://www.nature.com/articles/323533a0", 
    "citation": "13951", 
    "ID": "RNN", 
    "names": [
      {
        "params": 0.0, 
        "name": "recurrent neural network"
      }
    ]
  }, 
  {
    "date": "1997.12.15", 
    "training": [], 
    "parents": [
      {
        "link_info_l": "also learn how to forget previous input", 
        "ID": "MTRNN", 
        "link_info_s": ""
      }
    ], 
    "architecture": [], 
    "application": [
      "1.2.NLP"
    ], 
    "url": "https://www.mitpressjournals.org/doi/abs/10.1162/neco.1997.9.8.1735", 
    "citation": "8136", 
    "ID": "LSTM", 
    "names": [
      {
        "params": 0.0, 
        "name": "long short term memory"
      }
    ]
  }, 
  {
    "date": "2014.06.03", 
    "training": [], 
    "parents": [
      {
        "link_info_l": "input, forget, output gates=>reset, update gates", 
        "ID": "LSTM", 
        "link_info_s": ""
      }
    ], 
    "architecture": [], 
    "application": [
      "1.2.NLP"
    ], 
    "url": "https://arxiv.org/abs/1406.1078", 
    "citation": "2069", 
    "ID": "GRU", 
    "names": [
      {
        "params": 0.0, 
        "name": "gated recurrent unit"
      }
    ]
  }, 
  {
    "date": "1997.12.01", 
    "training": [], 
    "parents": [
      {
        "link_info_l": "future information cannot be reached from current state => get information from both past and future", 
        "ID": "RNN", 
        "link_info_s": ""
      }
    ], 
    "architecture": [], 
    "application": [
      "1.2.NLP"
    ], 
    "url": "http://ieeexplore.ieee.org/abstract/document/650093/", 
    "citation": "984", 
    "ID": "BRNN", 
    "names": [
      {
        "params": 0.0, 
        "name": "bidirectional recurrent neural network"
      }
    ]
  }, 
  {
    "date": "2013.08.04", 
    "training": [], 
    "parents": [
      {
        "link_info_l": "increase deepth to improve performance", 
        "ID": "RNN", 
        "link_info_s": ""
      }
    ], 
    "architecture": [], 
    "application": [
      "1.2.NLP"
    ], 
    "url": "https://arxiv.org/abs/1308.0850", 
    "citation": "972", 
    "ID": "stacked RNN", 
    "names": []
  }, 
  {
    "date": "2014.09.01", 
    "training": [], 
    "parents": [
      {
        "link_info_l": "attention mechanism to search relevant parts in the context", 
        "ID": "seq2seq", 
        "link_info_s": ""
      }
    ], 
    "architecture": [], 
    "application": [
      "1.2.NLP"
    ], 
    "url": "https://arxiv.org/abs/1409.0473", 
    "citation": "2081", 
    "ID": "attention RNN", 
    "names": []
  }, 
  {
    "date": "1990.11.01", 
    "training": [], 
    "parents": [
      {
        "link_info_l": "generalize RNN from chain-like structure to tree-like structure", 
        "ID": "RNN", 
        "link_info_s": ""
      }
    ], 
    "architecture": [], 
    "application": [
      "1.2.NLP"
    ], 
    "url": "https://www.sciencedirect.com/science/article/pii/000437029090005K", 
    "citation": "1050", 
    "ID": "recursive", 
    "names": [
      {
        "params": 0.0, 
        "name": "recursive neural network"
      }
    ]
  }, 
  {
    "date": "", 
    "training": [], 
    "parents": [
      {
        "link_info_l": "build both \ufb01ne and coarse time scales", 
        "ID": "RNN", 
        "link_info_s": ""
      }
    ], 
    "architecture": [], 
    "application": [
      "1.2.NLP"
    ], 
    "url": "", 
    "citation": "", 
    "ID": "MTRNN", 
    "names": [
      {
        "params": 0.0, 
        "name": "multi time scale recurrent neural network"
      }
    ]
  }, 
  {
    "date": "2014.09.10", 
    "training": [], 
    "parents": [
      {
        "link_info_l": "introduce a RNN to map squence to sequence", 
        "ID": "RNN", 
        "link_info_s": ""
      }
    ], 
    "architecture": [], 
    "application": [
      "1.2.NLP"
    ], 
    "url": "https://arxiv.org/abs/1409.3215", 
    "citation": "2829", 
    "ID": "seq2seq", 
    "names": []
  }, 
  {
    "date": "2017.05.08", 
    "training": [], 
    "parents": [
      {
        "link_info_l": "introduce a CNN to map sequence to sequence", 
        "ID": "seq2seq", 
        "link_info_s": ""
      }
    ], 
    "architecture": [], 
    "application": [
      "1.2.NLP"
    ], 
    "url": "https://arxiv.org/abs/1705.03122", 
    "citation": "73", 
    "ID": "conv seq2seq", 
    "names": []
  }, 
  {
    "date": "2013.12.20", 
    "training": [], 
    "parents": [
      {
        "link_info_l": "decomposing the state of an RNN into multiple layers", 
        "ID": "stacked RNN", 
        "link_info_s": ""
      }
    ], 
    "architecture": [], 
    "application": [
      "1.2.NLP"
    ], 
    "url": "https://arxiv.org/abs/1312.6026", 
    "citation": "269", 
    "ID": "MLP_RNN", 
    "names": []
  }, 
  {
    "date": "2004.04.02", 
    "training": [], 
    "parents": [
      {
        "link_info_l": "reservior computing to set the recurrent weights and only learn the output weights", 
        "ID": "RNN", 
        "link_info_s": ""
      }
    ], 
    "architecture": [], 
    "application": [
      "1.2.NLP"
    ], 
    "url": "http://science.sciencemag.org/content/304/5667/78", 
    "citation": "1517", 
    "ID": "ESN", 
    "names": [
      {
        "params": 0.0, 
        "name": "echo state network"
      }
    ]
  }
]