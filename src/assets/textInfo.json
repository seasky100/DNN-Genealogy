{
    "U-Net": {
        "info": " ",
        "fullname": "U-Net",
        "links": [
            [
                "U-Net: Convolutional Networks for Biomedical Image Segmentation",
                "https://arxiv.org/abs/1505.04597"
            ]
        ]
    },
    "FCN": {
        "info": "FCNs only have convolutional and pooling layers which give them the ability to make segmentations on arbitrary-sized inputs.",
        "fullname": "FCN",
        "links": [
            [
                "Fully Convolutional Networks for Semantic Segmentation",
                "https://arxiv.org/abs/1411.4038"
            ]
        ]
    },
    "SegNet": {
        "info": "SgeNet is a deep fully convolutional neural network architecture for semantic pixel-wise segmentation. The novelty of SegNet is that he decoder uses pooling indices computed in the max-pooling step of the corresponding encoder to perform non-linear upsampling. This eliminates the need for learning to upsample.",
        "fullname": "SegNet",
        "links": [
            [
                "SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation",
                "https://arxiv.org/abs/1511.00561"
            ]
        ]
    },
    "DeconvNet": {
        "info": "DeconvNet is a novel semantic segmentation algorithm by learning a deconvolution network. The decoder is composed of deconvolution and unpooling layers.",
        "fullname": "DeconvNet",
        "links": [
            [
                "Learning deconvolution network for semantic segmentation",
                "https://arxiv.org/abs/1505.04366"
            ]
        ]
    },
    "RedNet": {
        "info": "In RedNet, the residual module is applied to both the encoder and decoder as the basic building block, and the skip-connection is used to bypass the spatial feature between the encoder and decoder. In order to incorporate the depth information of the scene, a fusion structure is constructed, which makes inference on RGB image and depth image separately, and fuses their features over several layers. In order to efficiently optimize the network's parameters, a `pyramid supervision' training scheme is proposed to apply supervised learning over different layers in the decoder.",
        "fullname": "residual encoder decoder network",
        "links": [
            [
                "RedNet: Residual Encoder-Decoder Network for indoor RGB-D Semantic Segmentation",
                "https://arxiv.org/abs/1806.01054"
            ]
        ]
    },
    "RefineNet": {
        "info": "RefineNet is a generic multi-path refinement network that explicitly exploits all the information available along the down-sampling process to enable high-resolution prediction using long-range residual connections.",
        "fullname": "RefineNet",
        "links": [
            [
                "RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation",
                "https://arxiv.org/abs/1611.06612"
            ]
        ]
    },
    "PSPNet": {
        "info": "In this paper, we exploit the capability of global context information by different-region-based context aggregation through our pyramid pooling module together with the proposed pyramid scene parsing network.",
        "fullname": "PSPNet",
        "links": [
            [
                "Pyramid Scene Parsing Network",
                "https://arxiv.org/abs/1612.01105"
            ]
        ]
    },
    "DilatedNet": {
        "info": "",
        "fullname": "DilatedNet",
        "links": [
            [
                "Multi-Scale Context Aggregation by Dilated Convolutions",
                "https://arxiv.org/abs/1511.07122"
            ]
        ]
    },
    "DeepLab": {
        "info": "To overcome the poor localization property of DCNNs in segmentation tasks, this work combines the responses at the final DCNN layer with a fully connected Conditional Random Field (CRF)",
        "fullname": "DeepLab",
        "links": [
            [
                "Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs",
                "https://arxiv.org/abs/1412.7062"
            ]
        ]
    },
    "DeepLab_v2": {
        "info": "This work makes three contributions for the image semantic segmentation task: highlight the importance of using atrous/dilated convolutions; propose atrous spatial pyramid pooling (ASPP); use Fully connected CRF",
        "fullname": "DeepLab_v2",
        "links": [
            [
                "DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs",
                "https://arxiv.org/abs/1606.00915"
            ]
        ]
    },
    "GCN": {
        "info": "This work proves that large kernel is important for segmentation tasks. Since large kernel is computationally expensive, k x k convolution is approximated with sum of 1 x k + k x 1 and k x 1 and 1 x k convolutions, which is called global convolutional networks (GCN). It also suggests a residual-based boundary refinement to further refine the object boundaries. ",
        "fullname": "global convolutional network",
        "links": [
            [
                "Large Kernel Matters -- Improve Semantic Segmentation by Global Convolutional Network",
                "https://arxiv.org/abs/1703.02719"
            ]
        ]
    },
    "DeepLab_v3": {
        "info": "This works employs atrous convolution in cascade or in parallel to capture multi-scale context by adopting multiple atrous rates. Furthermore, it proposes to augment the previously proposed Atrous Spatial Pyramid Pooling module (in DeepLab_v2) with image-level features encoding global context and further boost performance. ",
        "fullname": "DeepLab_v3",
        "links": [
            [
                "Rethinking Atrous Convolution for Semantic Image Segmentation",
                "https://arxiv.org/abs/1706.05587"
            ]
        ]
    },
    
    "leaky units": {
        "info": "A leaky unit appends a self-connection to a hidden unit. A parameter alpha is used for calculating the moving average which memorizes both the past and the present.",
        "fullname": "leaky units",
        "links": [
            [
                "Advances in Optimizing Recurrent Networks",
                "http://ieeexplore.ieee.org/abstract/document/6639349/"
            ],
            [
                "Induction of Multiscale Temporal Structure",
                "http://papers.nips.cc/paper/522-induction-of-multiscale-temporal-structure.pdf"
            ],
            [
                "Hierarchical Recurrent Neural Networks for Long-Term Dependencies",
                "http://papers.nips.cc/paper/1102-hierarchical-recurrent-neural-networks-for-long-term-dependencies.pdf"
            ]
        ]
    },
    "diracNet": {
        "info": "DiracNets propose a simple weight parameterization, which allows to train very deep plain networks without explicit skip-connections. ",
        "fullname": "diracNet",
        "links": [
            [
                "DiracNets: Training Very Deep Neural Networks Without Skip-Connections",
                "https://arxiv.org/abs/1706.00388"
            ]
        ]
    },
    "highwayNets": {
        "info": "HighwahNets is a new architecture designed to ease gradient-based training of very deep networks. The architecture allows information flow over layers and uses gating units to regulate the flow.",
        "fullname": "highwayNets",
        "links": [
            [
                "Highway Networks",
                "https://arxiv.org/pdf/1505.00387.pdf"
            ],
            [
                "Highway and Residual Networks learn Unrolled Iterative Estimation",
                "http://arxiv.org/abs/1612.07771"
            ]
        ]
    },
    "CW-RNN": {
        "info": "A Clockwork RNN partitions the hidden layers in an RNN into separate modules, each of which processes inputs at its own temporal granularity and computes only at its clock rate.",
        "fullname": "CW-RNN",
        "links": [
            [
                "A Clockwork RNN",
                "https://arxiv.org/pdf/1402.3511.pdf"
            ],
            [
                "Spatial Clockwork Recurrent Neural Network for Muscle Perimysium Segmentation",
                "https://link.springer.com/chapter/10.1007/978-3-319-46723-8_22"
            ]
        ]
    },
    "fractalNet": {
        "info": "fractalNet introduce an architecture design strategy that repeatedly applies an expansion rule to generate a DNN. It proves that ultra-deep NNs with residual connections are possible",
        "fullname": "fractalNet",
        "links": [
            [
                "Fractalnet: ultra-deep neural networks without residuals",
                "https://arxiv.org/abs/1605.07648"
            ],
            [
                "3D FractalNet: Dense Volumetric Segmentation for Cardiovascular MRI Volumes",
                "https://link.springer.com/chapter/10.1007/978-3-319-52280-7_10"
            ]
        ]
    },
    "DPN": {
        "info": "DPN proposes a new topology of connection paths internally by evealing the equivalence of the ResNet and DenseNet.",
        "fullname": "DPN",
        "links": [
            [
                "Dual Path Networks",
                "https://arxiv.org/pdf/1707.01629.pdf"
            ]
        ],
        "code": [
            [
                "MxNet",
                "https://github.com/cypw/DPNs"
            ]
        ]
    },
    "LSTM": {
        "info": "A long short-team memory is one of the gated RNNs which allow the network to forget the old state besides accumulation infomation. The self-loop RNN in an LSTM is conditioned on the context by a group of layers.",
        "fullname": "LSTM",
        "links": [
            [
                "Long Short-Term Memory",
                "https://www.mitpressjournals.org/doi/abs/10.1162/neco.1997.9.8.1735"
            ],
            [
                "LSTM: A Search Space Odyssey",
                "http://ieeexplore.ieee.org/abstract/document/7508408/"
            ],
            [
                "Show and Tell: A Neural Image Caption Generator",
                "https://www.cv-foundation.org/openaccess/content_cvpr_2015/app/2A_101.pdf"
            ],
            [
                "Speech recognition with deep recurrent neural networks",
                "http://ieeexplore.ieee.org/abstract/document/6638947/"
            ],
            [
                "Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks",
                "http://papers.nips.cc/paper/3449-offline-handwriting-recognition-with-multidimensional-recurrent-neural-networks"
            ]
        ]
    },
    "BRNN": {
        "info": "A bidirectional RNN combines an RNN that moves forward with another RNN that moves backward.  It is used for making predictions that depend on the whole input sequence.",
        "fullname": "BRNN",
        "links": [
            [
                "Bidirectional recurrent neural networks",
                "http://ieeexplore.ieee.org/abstract/document/650093/"
            ],
            [
                "Neural Machine Translation by Jointly Learning to Align and Translate",
                "https://arxiv.org/abs/1409.0473"
            ],
            [
                "A Novel Connectionist System for Unconstrained Handwriting Recognition",
                "http://ieeexplore.ieee.org/abstract/document/4531750/"
            ],
            [
                "Hierarchical Recurrent Neural Network for Skeleton Based Action Recognition",
                "https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Du_Hierarchical_Recurrent_Neural_2015_CVPR_paper.pdf"
            ],
            [
                "Exploiting the Past and the Future in Protein Secondary Structure Prediction",
                "https://academic.oup.com/bioinformatics/article/15/11/937/249908"
            ]
        ]
    },
    "tree-LSTM": {
        "info": "A tree LSTM is a generalization of LSTM with a tree-structured network topology.",
        "fullname": "tree-LSTM",
        "links": [
            [
                "Enhanced LSTM for Natural Language Inference",
                "https://arxiv.org/abs/1609.06038"
            ],
            [
                "Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks",
                "https://arxiv.org/abs/1503.00075"
            ]
        ]
    },
    "DT-RNN": {
        "info": "A deep transition RNN appends an MLP with one or more layers in hidden-to-hidden transition to an RNN.",
        "fullname": "DT-RNN",
        "links": [
            [
                "How to Construct Deep Recurrent Neural Networks",
                "https://arxiv.org/abs/1312.6026"
            ]
        ]
    },
    "DT(S)-RNN": {
        "info": "A deep transition RNN with shortcut appends input-to-hidden shortcut connections to a DT-RNN.",
        "fullname": "DT(S)-RNN",
        "links": [
            [
                "How to Construct Deep Recurrent Neural Networks",
                "https://arxiv.org/abs/1312.6026"
            ]
        ]
    },
    "recursive": {
        "info": "A recursive neural network is a generalization of recurrent network with a tree-structured computational graph. The depth is reduced from n to log(n), which may help deal with long-term dependencies.",
        "fullname": "recursive",
        "links": [
            [
                "Recursive Distributed Representations",
                "http://129.64.46.116/papers/raam.pdf"
            ],
            [
                "A General Framework for Adaptive Processing of Data Structures",
                "http://ieeexplore.ieee.org/abstract/document/712151/"
            ],
            [
                "Parsing Natural Scenes and Natural Language with Recursive Neural Networks",
                "https://nlp.stanford.edu/pubs/SocherLinNgManning_ICML2011.pdf"
            ],
            [
                "Semi-supervised Recursive Autoencoders for Predicting Sentiment Distributions",
                "https://dl.acm.org/citation.cfm?id=2145450"
            ],
            [
                "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
                "http://www.aclweb.org/anthology/D13-1170"
            ]
        ]
    },
    "VGG": {
        "info": "VGGNet consists of 16/19 convolutional layers and has a highly modularized architecture. It stacks small size convolutional layers to increase the depth. ",
        "fullname": "VGG",
        "links": [
            [
                "ImageNet Classification with Deep Convolutional Neural Networks",
                "https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks"
            ]
        ]
    },
    "alexNet": {
        "info": "In 2012, AlexNet significantly outperformed all the prior competitors and won the ImageNet LSVRC challenge.  It has a similar structure as LeNet, but it changes the activation function from Sigmoid to Relu and uses dropout to deal with overfitting. Traning on two GPUs enables AlexNet to learn from a large amount of data.",
        "fullname": "alexNet",
        "links": [
            [
                "ImageNet Classification with Deep Convolutional Neural Networks",
                "https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks"
            ]
        ]
    },
    "mixNet": {
        "info": "Two forms of connections, additon and concatenation, have the superiority and insufficiency. To combine their advantages and avoid certain limitations on representation learning, we present a highly efficient and modularized Mixed Link Network (MixNet) which is equipped with flexible inner link (addition) and outer link (concatenation) modules. ",
        "fullname": "mixNet",
        "links": [
            [
                "Mixed Link Networks",
                "https://arxiv.org/abs/1802.01808"
            ]
        ]
    },
    "GRU": {
        "info": "A gated recurrent unit is one of the gated RNNs, including an update gate and a reset gate.",
        "fullname": "GRU",
        "links": [
            [
                "An Empirical Exploration of Recurrent Network Architectures",
                "http://proceedings.mlr.press/v37/jozefowicz15.pdf"
            ],
            [
                "Gate-Variants of Gated Recurrent Unit (GRU) Neural Networks",
                "http://ieeexplore.ieee.org/iel7/8039346/8052834/08053243.pdf"
            ],
            [
                "Video Paragraph Captioning Using Hierarchical Recurrent Neural Networks",
                "https://www.cv-foundation.org/openaccess/content_cvpr_2016/app/S19-04.pdf"
            ],
            [
                "Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling",
                "https://arxiv.org/abs/1412.3555"
            ],
            [
                "Document Modeling with Gated Recurrent Neural Network for Sentiment Classification",
                "http://www.aclweb.org/anthology/D15-1167"
            ]
        ]
    },
    "attention": {
        "info": "The attention mechanism is based on the seq2seq model, in which multiple vector Cs are generated from the hidden units of the input sentence.",
        "fullname": "attention",
        "links": [
            [
                "End-to-end attention-based large vocabulary speech recognition",
                "http://ieeexplore.ieee.org/abstract/document/7472618/"
            ],
            [
                "Effective Approaches to Attention-based Neural Machine Translation",
                "https://arxiv.org/abs/1508.04025"
            ],
            [
                "Neural Machine Translation by Jointly Learning to Align and Translate",
                "https://arxiv.org/abs/1409.0473"
            ],
            [
                "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention",
                "http://proceedings.mlr.press/v37/xuc15.pdf"
            ]
        ]
    },
    "RNN": {
        "info": "Vanilla RNN is a simple recurrent neural network is used for processing sequences of variable length, in which a state contains information about the whole past sequence. It shares same parameters across different time steps of the sequence.",
        "fullname": "RNN",
        "links": [
            [
                "Finding Structure in Time",
                "http://onlinelibrary.wiley.com/doi/10.1207/s15516709cog1402_1/full"
            ],
            [
                "Recurrent Neural Network Based Language Model",
                "http://www.isca-speech.org/archive/interspeech_2010/i10_1045.html"
            ],
            [
                "DRAW: A Recurrent Neural Network For Image Generation",
                "https://arxiv.org/abs/1502.04623"
            ],
            [
                "A Critical Review of Recurrent Neural Networks for Sequence Learning",
                "https://arxiv.org/abs/1506.00019"
            ]
        ]
    },
    "ESN with leaky units": {
        "info": "An ESN with leaky units appends an ESN by leaky integration units.",
        "fullname": "ESN with leaky units",
        "links": [
            [
                "A Novel Model of Leaky Integrator Echo State Network for Time-Series Prediction",
                "https://www.sciencedirect.com/science/article/pii/S0925231215001782"
            ],
            [
                "Optimization and Applications of Echo State Networks with Leaky-Integrator Neurons",
                "https://www.sciencedirect.com/science/article/pii/S089360800700041X"
            ]
        ]
    },
    "seq2seq": {
        "info": "A sequence to sequence model is mainly used for translation. The model reads the input sentence into a vector C and decomposes C into translation. It is also known as encoder-decoder model.",
        "fullname": "seq2seq",
        "links": [
            [
                "Multi-task Sequence to Sequence Learning",
                "https://arxiv.org/abs/1511.06114"
            ],
            [
                "Sequence to Sequence Learning with Neural Networks",
                "https://arxiv.org/abs/1409.3215"
            ],
            [
                "Massive Exploration of Neural Machine Translation Architectures",
                "https://arxiv.org/abs/1703.03906"
            ],
            [
                "On the Properties of Neural Machine Translation: Encoder-Decoder Approaches",
                "https://arxiv.org/abs/1409.1259"
            ],
            [
                "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
                "https://arxiv.org/abs/1406.1078"
            ]
        ]
    },
    "SENet": {
        "info": "To boost the representational power of a network, SENet proposes a novel architectural unit, squeeze-and-excitation, to recalibrates channel-wise feature responses. It won ILSVRC 2017 classification.",
        "fullname": "SENet",
        "links": [
            [
                "Squeeze-and-Excitation Networks",
                "https://arxiv.org/abs/1709.01507"
            ]
        ]
    },
    "mobileNet": {
        "info": "MoblieNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. It has only two global hyper-parameters that are easy to set.",
        "fullname": "mobileNet",
        "links": [
            [
                "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications",
                "https://arxiv.org/abs/1704.04861"
            ]
        ]
    },
    "conv seq2seq": {
        "info": "A convolution sequence to sequence model applys CNN structure to map sequence to sequence. It has a faster speed and a high accuracy.",
        "fullname": "conv seq2seq",
        "links": [
            [
                "Attention is All you Need",
                "http://papers.nips.cc/paper/7181-attention-is-all-you-need"
            ],
            [
                "Convolutional Sequence to Sequence Learning",
                "https://arxiv.org/abs/1705.03122"
            ],
            [
                "A Convolutional Encoder Model for Neural Machine Translation",
                "https://arxiv.org/abs/1611.02344"
            ]
        ]
    },
    "leNet": {
        "info": "LeNet-5 is a pioneering 7-level convolutional network proposed by LeCun et al in 1998. It recognises hand-written numbers in 32x32 pixel images. ",
        "fullname": "leNet",
        "links": [
            [
                "Gradient-based learning applied to document recognition",
                "http://ieeexplore.ieee.org/abstract/document/726791/"
            ]
        ]
    },
    "inception": {
        "info": "Inception is a multi-branch module proposed in GoogleNet. This architecture consists of 22 layers and significantly reduces the number of parameters from 60M (AlexNet) to 4M",
        "fullname": "inception",
        "links": [
            [
                "Going deeper with convolutions",
                "https://arxiv.org/abs/1409.4842"
            ],
            [
                "Rethinking the Inception Architecture for Computer Vision",
                "https://arxiv.org/abs/1512.00567"
            ],
            [
                "Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning",
                "https://arxiv.org/abs/1602.07261"
            ]
        ]
    },
    "inception_resNet": {
        "info": "Inception is a multi-branch module proposed in GoogleNet. This architecture consists of 22 layers and significantly reduces the number of parameters from 60M (AlexNet) to 4M",
        "fullname": "inception_resNet",
        "links": [
            [
                "Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning",
                "https://arxiv.org/abs/1602.07261"
            ],
            [
                "Going deeper with convolutions",
                "https://arxiv.org/abs/1409.4842"
            ],
            [
                "Rethinking the Inception Architecture for Computer Vision",
                "https://arxiv.org/abs/1512.00567"
            ]
        ]
    },
    "ESN": {
        "info": "An echo state network is used for solving vanishing/exploding problems, in which recurrent hidden units are set and only output weight are learnt.",
        "fullname": "ESN",
        "links": [
            [
                "Minimum Complexity Echo State Network",
                "http://ieeexplore.ieee.org/abstract/document/5629375/"
            ],
            [
                "Adaptive Nonlinear System Identification with Echo State Networks",
                "http://papers.nips.cc/paper/2318-adaptive-nonlinear-system-identification-with-echo-state-networks.pdf"
            ],
            [
                "Long Short-Term Memory in Echo State Networks: Details of a Simulation Study",
                "https://opus.jacobs-university.de/frontdoor/index/index/docId/638"
            ],
            [
                "Harnessing Nonlinearity: Predicting Chaotic Systems and Saving Energy in Wireless Communication",
                "http://science.sciencemag.org/content/304/5667/78"
            ]
        ]
    },
    "denseNet": {
        "info": "Based on the observation that CNNs are more accurate and efficient to train if they contain shorter connections between layers, DenseNet connects each layer to every other layer in a feed-forward fashion. DenseNets alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters.",
        "fullname": "denseNet",
        "links": [
            [
                "Densely Connected Convolutional Networks",
                "https://arxiv.org/abs/1608.06993"
            ],
            [
                "DenseNet for Dense Flow",
                "https://arxiv.org/abs/1707.06316"
            ]
        ]
    },
    "DB-LSTM": {
        "info": "A deep bidirectional LSTM combines a deep bidirectional RNN and a LSTM.",
        "fullname": "DB-LSTM",
        "links": [
            [
                "Speech Recognition with Deep Recurrent Neural Networks",
                "https://arxiv.org/abs/1303.5778"
            ],
            [
                "Hybrid Speech Recognition with Deep Bidirectional LSTM",
                "http://ieeexplore.ieee.org/abstract/document/6707742/"
            ],
            [
                "Towards End-to-End Speech Recognition with Recurrent Neural Networks",
                "http://proceedings.mlr.press/v32/graves14.pdf"
            ],
            [
                "Long Short-Term Memory Recurrent Neural Network Architectures for Large Scale Acoustic Modeling",
                "http://www.isca-speech.org/archive/interspeech_2014/i14_0338.html"
            ]
        ]
    },
    "xception": {
        "info": "The authors present an interpretation of Inception modules as a depthwise convolution followed by a pointwise convolution. This observation leads to a novel CNN architecture inspired by Inception, where Inception modules have been replaced with depthwise separable convolutions.",
        "fullname": "xception",
        "links": [
            [
                "Xception: Deep Learning with Depthwise Separable Convolutions",
                "https://arxiv.org/abs/1610.02357"
            ]
        ]
    },
    "resNeXt": {
        "info": "ResNeXt is a simple, highly modularized network architecture that has only a few hyper-parameters. exposes a new dimension, calleda as cardinality (the size of the set of transformations). ",
        "fullname": "resNeXt",
        "links": [
            [
                "Aggregated Residual Transformations for Deep Neural Networks",
                "https://arxiv.org/abs/1611.05431"
            ]
        ]
    },
    "resNet": {
        "info": "ResNet proposes an architecture that adds skip connections over layers. ResNets are easier to optimize, and can gain accuracy from considerably increased depth.",
        "fullname": "resNet",
        "links": [
            [
                "Deep Residual Learning for Image Recognition",
                "https://arxiv.org/abs/1512.03385"
            ],
            [
                "Identity Mappings in Deep Residual Networks",
                "http://arxiv.org/abs/1603.05027"
            ],
            [
                "Identity Matters in Deep Learning",
                "http://arxiv.org/abs/1611.04231"
            ],
            [
                "Wider or Deeper: Revisiting the ResNet Model for Visual Recognition",
                "http://arxiv.org/abs/1611.10080"
            ],
            [
                "Residual Networks Behave Like Ensembles of Relatively Shallow Networks",
                "http://arxiv.org/abs/1605.06431"
            ]
        ]
    },
    "DGLSTM": {
        "info": "A depth-gated LSTM appends depth gates to adjacent layers in LSTM. It performs better in machine translation and language modeling.",
        "fullname": "DGLSTM",
        "links": [
            [
                "Depth-Gated Recurrent Neural Networks",
                "https://pdfs.semanticscholar.org/d3e9/9f2f98ac361aded0b9b9d90b6f9fe8bbbc70.pdf"
            ],
            [
                "Long Short-Term Memory-Networks for Machine Reading",
                "https://arxiv.org/abs/1601.06733"
            ],
            [
                "Highway Long Short-Term Memory RNNS for Distant Speech Recognition",
                "http://ieeexplore.ieee.org/abstract/document/7472780/"
            ]
        ]
    },
    "nasNet": {
        "info": "NasNet automatically learns the DNN architcture design by searching through an architecture design space. This architecture design space consists of a set of operations collected based on their prevalence in the CNN literature. The architecture learnt on a small dataset can be transfered to a large dataset.",
        "fullname": "nasNet",
        "links": [
            [
                "Learning Transferable Architectures for Scalable Image Recognition",
                "https://arxiv.org/abs/1707.07012"
            ],
            [
                "Neural Architecture Search with Reinforcement Learning",
                "https://arxiv.org/abs/1611.01578"
            ]
        ],
        "code": [
            [
                "tensorflow",
                "https://github.com/tensorflow/models/blob/master/research/slim/nets/nasnet/nasnet.py"
            ],
            [
                "keras",
                "https://github.com/titu1994/Keras-NASNet"
            ]
        ]
    },
    "stacked RNN": {
        "info": "A stacked RNN stacks more recurrent hidden layers in an RNN to make it deeper. It is also known as deep RNN.",
        "fullname": "stacked RNN",
        "links": [
            [
                "Speech Recognition with Deep Recurrent Neural Networks",
                "https://arxiv.org/abs/1303.5778"
            ],
            [
                "Learning Complex, Extended Sequences Using the Principle of History Compression",
                "http://ieeexplore.ieee.org/document/6795261/"
            ],
            [
                "EESEN: End-to-end Speech Recognition Using Deep RNN Models and WFST-based Decoding",
                "http://ieeexplore.ieee.org/abstract/document/7404790/"
            ],
            [
                "Singing-voice Separation from Monaural Recordings Using Deep Recurrent Neural Networks",
                "http://cal.cs.illinois.edu/papers/huang-ismir2014.pdf"
            ]
        ]
    },
    "time skip connections": {
        "info": "An RNN with time skip connections adds direct connections from variables in the distant past to variables in the present, in order to transfer information more efficiently.",
        "fullname": "time skip connections",
        "links": [
            [
                "Interactive Language Understanding with Multiple Timescale Recurrent Neural Networks",
                "https://link.springer.com/chapter/10.1007/978-3-319-11179-7_25"
            ],
            [
                "Developmental Human-Robot Imitation Learning of Drawing with a Neuro Dynamical System",
                "http://ieeexplore.ieee.org/abstract/document/6722152/"
            ],
            [
                "Learning Long-Term Dependencies is Not as Difficult With NARX Recurrent Neural Networks",
                "https://drum.lib.umd.edu/handle/1903/745"
            ],
            [
                "Analysing the Multiple Timescale Recurrent Neural Network for Embodied Language Understanding",
                "https://link.springer.com/chapter/10.1007/978-3-319-09903-3_8"
            ]
        ]
    },
    "squeezeNet": {
        "info": "SqueezeNet is a smaller architecture that achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters.",
        "fullname": "squeezeNet",
        "links": [
            [
                "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size",
                "https://arxiv.org/abs/1602.07360"
            ]
        ]
    },
    "polyInception": {
        "info": "PolyInception is a new family of modules that extend inception residual units. PolyInception generalizes the additive combination in Inception residual units via various forms of polynomial compositions to encourage the structural diversity and enhance the expressive power",
        "fullname": "polyInception",
        "links": [
            [
                "PolyNet: A Pursuit of Structural Diversity in Very Deep Networks",
                "https://arxiv.org/pdf/1611.05725"
            ]
        ],
        "code": [
            [
                "caffe",
                "https://github.com/CUHK-MMLAB/polynet"
            ]
        ]
    },
    "WRN": {
        "info": "Wide Residual Networks (WRN) is a novel architecture which decrease depth and increase width of ResNet blocks. A simple 16-layer WRN outperforms in accuracy and efficiency all previous deep residual networks, achieving new state-of-the-art results on CIFAR, SVHN, and COCO",
        "fullname": "Wide ResNet",
        "links": [
            [
                "Wide Residual Networks",
                "http://arxiv.org/abs/1605.07146"
            ]
        ],
        "code": [
            [
                "Torch",
                "https://github.com/szagoruyko/wide-residual-networks"
            ],
            [
                "Keras",
                "https://github.com/titu1994/Wide-Residual-Networks"
            ]
        ]
    },
    "RIR": {
        "info": "Resnet in Resnet (RiR) is a deep dual-stream architecture that generalizes ResNets and standard CNNs. RiR is easily implemented with no computational overhead. RiR consistently improves performance over ResNets, outperforms architectures with similar amounts of augmentation on CIFAR-10, and establishes a new state-of-the-art on CIFAR-100.",
        "fullname": "ResNet in ResNet",
        "links": [
            [
                "Resnet in Resnet: Generalizing Residual Architectures",
                "https://arxiv.org/abs/1603.08029"
            ]
        ],
        "code": []
    },
    "SRU": {
        "info": "Simple Recurrent Unit (SRU) architecture is a recurrent unit that simplifies the computation by exposing more parallelism. In SRU, the majority of computation for each step is independent of the recurrence and can be easily parallelized. SRU is as fast as a convolutional layer and 5-10x faster than an optimized LSTM. SRUs can be used in a wide range of applications.",
        "fullname": "Simple Reccurent Unit",
        "links": [
            [
                "TRAINING RNNS AS FAST AS CNNS",
                "https://arxiv.org/pdf/1709.02755"
            ]
        ],
        "code": [
            [
                "PyTorch",
                "https://github.com/taolei87/sru"
            ],
            [
                "CNTK",
                "https://github.com/taolei87/sru"
            ]
        ]
    },
    "LRU": {
        "info": "Lattice Recurrent Unit(LRU) is an adaptation of GRUs to a lattice multi-dimensional architecture. LRU decouples the recurrent units to enable infomration flow for both time and depth dimensions. LRU enables better convergence and accuracy.",
        "fullname": "Lattice Recurrent Unit",
        "links": [
            [
                "Lattice Recurrent Unit: Improving Convergence and Statistical Efficiency for Sequence Modeling",
                "https://arxiv.org/pdf/1710.02254"
            ],
            [
                "Lattice-Based Recurrent Neural Network Encoders for Neural Machine Translation",
                "http://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14320/14220"
            ]
        ],
        "code": [
            [
                "PyTorch",
                "https://github.com/chahuja/lru"
            ]
        ]
    },
    "gridLSTM": {
        "info": "Grid Long Short-Term Memory is a network where LSTM cells are arranged in a multidimensional grid. It can be applied to vectors, sequences or higher dimensional data. 2D LSTM achieved the state-of-the-art performance on Wikipedia character prediction benchmark. ",
        "fullname": "Grid Long Short-term Memory",
        "links": [
            [
                "Grid Long Short-Term Memory",
                "https://arxiv.org/abs/1507.01526"
            ]
        ]
    },
    "fast R-CNN": {
        "info": "ast R-CNN builds on previous work to efficiently classify object proposals using deep convolutional networks. Compared to previous work, Fast R-CNN employs several innovations to improve training and testing speed while also increasing detection accuracy. ",
        "fullname": "Fast R-CNN",
        "links": [
            [
                "Fast R-CNN",
                "https://arxiv.org/abs/1504.08083"
            ]
        ]
    },
    "faster R-CNN": {
        "info": "Faster R-CNN proposes a Region Proposal Network (RPN). RPN shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position.",
        "fullname": "Faster R-CNN/Region Proposal Network",
        "links": [
            [
                "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks",
                "https://arxiv.org/abs/1506.01497"
            ]
        ]
    },
    "YOLO": {
        "info": "YOLO is a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, YOLO frames object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. ",
        "fullname": "You Only Look Once",
        "links": [
            [
                "You Only Look Once: Unified, Real-Time Object Detection",
                "https://arxiv.org/abs/1506.02640"
            ]
        ]
    },
    "YOLO_v2": {
        "info": "YOLO v2 proposes various improvements to the YOLO detection method, including adding batch normalization, fine tuning high resolution classifier, using anchor boxes to predict bounding boxes, and adding a passthrough layer.",
        "fullname": "You Only Look Once V2",
        "links": [
            [
                "YOLO9000: Better, Faster, Stronger",
                "https://arxiv.org/abs/1612.08242"
            ]
        ]
    },
    "SSD": {
        "info": "SSD is a method for detecting objects in images using a single deep neural network. It discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. ",
        "fullname": "Single Shot MultiBox Detector",
        "links": [
            [
                "SSD: Single Shot MultiBox Detector",
                "https://arxiv.org/abs/1512.02325"
            ]
        ]
    },
    "DSSD": {
        "info": "DSSD is an approach for introducing additional context into state-of-the-art general object detection. A state-of-the-art classifier (Residual-101) is combined with a fast detection framework SSD. We then augment SSD+Residual-101 with deconvolution layers to introduce additional large-scale context in object detection and improve accuracy. ",
        "fullname": "Deconvolutional Single Shot Detector",
        "links": [
            [
                "DSSD : Deconvolutional Single Shot Detector",
                "https://arxiv.org/abs/1701.06659"
            ]
        ]
    },
    "DSOD": {
        "info": "DSOD is a framework that can learn object detectors from scratch. State-of-the-art object objectors rely heavily on networks pre-trained on large-scale classification datasets. ",
        "fullname": "Deeply Supervised Object Detectors",
        "links": [
            [
                "DSOD: Learning Deeply Supervised Object Detectors from Scratch",
                "https://arxiv.org/abs/1708.01241"
            ]
        ]
    },
    "R-FCN": {
        "info": "In contrast to previous region-based detectors such as Fast/Faster R-CNN that apply a costly per-region subnetwork hundreds of times, R-FCN is fully convolutional with almost all computation shared on the entire image. ",
        "fullname": "Region-based Fully Convolutional Networks",
        "links": [
            [
                "R-FCN: Object Detection via Region-based Fully Convolutional Networks",
                "https://arxiv.org/abs/1605.06409"
            ]
        ]
    },
    "FPN": {
        "info": "Feature pyramids are a basic component in recognition systems for detecting objects at different scales. But recent deep learning object detectors have avoided pyramid representations, in part because they are compute and memory intensive. In this paper, we exploit the inherent multi-scale, pyramidal hierarchy of deep convolutional networks to construct feature pyramids with marginal extra cost. ",
        "fullname": "Feature Pyramid Networks",
        "links": [
            [
                "Feature Pyramid Networks for Object Detection",
                "https://arxiv.org/abs/1612.03144"
            ]
        ]
    },
    "mask R-CNN": {
        "info": "Mask R-CNN detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance.",
        "fullname": "Mask R-CNN",
        "links": [
            [
                "Mask R-CNN",
                "https://arxiv.org/abs/1703.06870"
            ]
        ]
    },
    "R-CNN": {
        "info": "R-CNN is the first work to use CNNs for object detection. It improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012. It combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. ",
        "fullname": "Region-based convolutional neural network",
        "links":[
            [
                "Rich feature hierarchies for accurate object detection and semantic segmentation",
                "https://arxiv.org/abs/1311.2524"
            ]
        ]
    },
    "SPP-Net":{
        "info":"Existing deep convolutional neural networks (CNNs) require a fixed-size (e.g., 224x224) input image. SPP-Net, with the spatial pyramid pooling, can eliminate the above requirement and generate a fixed-length representation regardless of image size/scale. Pyramid pooling is also robust to object deformations.",
        "fullname":"Spatial Pyramid Pooling Networks",
        "links":[
            [
                "Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition",
                "https://arxiv.org/abs/1406.4729"
            ]
        ]
    }
}